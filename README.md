Disclaimer : Even though I've written the code myself, this project is heavily inspired by Andrej Karpathy's work.
What is in this repository ? : the GPT-2 Architecture from scratch and the model weights loaded from huggingface.
The GPT architecture has been written in accordance with the OpenAI architecture of the same model.
After tweaking the gptconfig() values you can load up the other gpt2 models weights from huggingface.
I haven't written code to store the weights locally, but I'm pretty sure that that is easy to do so.
The purpose of this repository was to use a mix of RLHF and a bit of intuitive code to train the model to act in a certain way.
